Mage ai files 

DATA LODER 

import io
import pandas as pd
import requests
if 'data_loader' not in globals():
    from mage_ai.data_preparation.decorators import data_loader
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test


@data_loader
def load_data_from_api(*args, **kwargs):
    """
    Template for loading data from API
    """
    url = 'https://storage.googleapis.com/taxi-data-analysis-shumehta/Final_dataset_taxi.csv'
    response = requests.get(url)

    return pd.read_csv(io.StringIO(response.text), sep=',')


@test
def test_output(output, *args) -> None:
    """
    Template code for testing the output of the block.
    """
    assert output is not None, 'The output is undefined'


DATA TRANSFORMER 

import pandas as pd
if 'transformer' not in globals():
    from mage_ai.data_preparation.decorators import transformer
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test


@transformer
def transform(df, *args, **kwargs):
    """
    Template code for a transformer block.

    Add more parameters to this function if this block has multiple parent blocks.
    There should be one parameter for each output variable from each parent block.

    Args:
        data: The output from the upstream parent block
        args: The output from any additional upstream blocks (if applicable)

    Returns:
        Anything (e.g. data frame, dictionary, array, int, str, etc.)
    """
    # Specify your transformation logic here
    df[['tpep_pickup_datetime', 'tpep_dropoff_datetime']] = df[['tpep_pickup_datetime', 'tpep_dropoff_datetime']].apply(pd.to_datetime)

    # Remove duplicates from the DataFrame and reset the index without adding the old index as a column.
    df = df.drop_duplicates().reset_index(drop=True)
    # Create a new column 'trip_id' which is just the new index of each row.
    df['trip_id'] = df.index

    # Extract only the pickup and dropoff datetime columns and reset the index to ensure alignment.
    datetime_dim = df[['tpep_pickup_datetime', 'tpep_dropoff_datetime']].copy()

    # Extract various datetime components from the pickup and dropoff datetime columns.
    datetime_features = ['hour', 'day', 'month', 'year', 'weekday']
    for feature in datetime_features:
        datetime_dim[f'pick_{feature}'] = datetime_dim['tpep_pickup_datetime'].dt.__getattribute__(feature)
        datetime_dim[f'drop_{feature}'] = datetime_dim['tpep_dropoff_datetime'].dt.__getattribute__(feature)

    # Assign a unique ID to each row in the datetime_dim DataFrame which is just its index.
    datetime_dim['datetime_id'] = datetime_dim.index

    # Reorder columns to match the specified order.
    columns_order = ['datetime_id', 'tpep_pickup_datetime'] + [f'pick_{feature}' for feature in datetime_features] + \
                    ['tpep_dropoff_datetime'] + [f'drop_{feature}' for feature in datetime_features]
    datetime_dim = datetime_dim[columns_order]

    # Create a dimension table for passenger counts
    passenger_count_dim = df[['passenger_count']].drop_duplicates().reset_index(drop=True)
    passenger_count_dim['passenger_count_id'] = passenger_count_dim.index

    # Create a dimension table for trip distances
    trip_distance_dim = df[['trip_distance']].drop_duplicates().reset_index(drop=True)
    trip_distance_dim['trip_distance_id'] = trip_distance_dim.index

    # Define a mapping dictionary for rate codes
    rate_code_type = {
        1: "Standard rate",
        2: "JFK",
        3: "Newark",
        4: "Nassau or Westchester",
        5: "Negotiated fare",
        6: "Group ride"
        }

    # Create a dimension table for rate codes
    rate_code_dim = df[['RatecodeID']].drop_duplicates().reset_index(drop=True)
    rate_code_dim['rate_code_id'] = rate_code_dim.index
    rate_code_dim['rate_code_name'] = rate_code_dim['RatecodeID'].map(rate_code_type)

    #reorder the columns
    rate_code_dim = rate_code_dim[['rate_code_id', 'RatecodeID', 'rate_code_name']]

    def create_location_dim(df, location_id_column, location_dim_name):
  
        location_dim = df[[location_id_column]].drop_duplicates().reset_index(drop=True)
        location_dim[location_dim_name] = location_dim.index
        return location_dim

    # Creating pickup and dropoff dimension tables
    pickup_location_dim = create_location_dim(df, 'PULocationID', 'pickup_location_id')
    dropoff_location_dim = create_location_dim(df, 'DOLocationID', 'dropoff_location_id')

    # Dictionary mapping payment types to descriptive names
    payment_type_name = {
        1: "Credit card",
        2: "Cash",
        3: "No charge",
        4: "Dispute",
        5: "Unknown",
        6: "Voided trip"
    }

    # Function to create a payment type dimension table
    def create_payment_type_dim(df, col_name, mapping_dict):

        payment_type_dim = df[[col_name]].drop_duplicates().reset_index(drop=True)
        payment_type_dim['payment_type_id'] = payment_type_dim.index
        payment_type_dim['payment_type_name'] = payment_type_dim[col_name].map(mapping_dict)
        return payment_type_dim[['payment_type_id', col_name, 'payment_type_name']]

    # Creating the payment type dimension table
    payment_type_dim = create_payment_type_dim(df, 'payment_type', payment_type_name)

    fact_table = df \
    .merge(passenger_count_dim, left_on='trip_id', right_on='passenger_count_id', how='left') \
    .merge(trip_distance_dim, left_on='trip_id', right_on='trip_distance_id', how='left') \
    .merge(rate_code_dim, left_on='RatecodeID', right_on='rate_code_id', how='left') \
    .merge(pickup_location_dim, left_on='PULocationID', right_on='pickup_location_id', how='left') \
    .merge(dropoff_location_dim, left_on='DOLocationID', right_on='dropoff_location_id', how='left') \
    .merge(datetime_dim, left_on='trip_id', right_on='datetime_id', how='left') \
    .merge(payment_type_dim, left_on='payment_type', right_on='payment_type_id', how='left') \
    .reindex(columns=['trip_id', 'VendorID', 'datetime_id', 'passenger_count_id',
                      'trip_distance_id', 'rate_code_id', 'store_and_fwd_flag', 'pickup_location_id', 
                      'dropoff_location_id', 'payment_type_id', 'fare_amount', 'extra', 'mta_tax', 
                      'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount'])

    return "success"



  


@test
def test_output(output, *args) -> None:
    """
    Template code for testing the output of the block.
    """
    assert output is not None, 'The output is undefined'

DATA EXPORTER

from mage_ai.settings.repo import get_repo_path
from mage_ai.io.bigquery import BigQuery
from mage_ai.io.config import ConfigFileLoader
from pandas import DataFrame
from os import path



if 'data_exporter' not in globals():
    from mage_ai.data_preparation.decorators import data_exporter


@data_exporter
def export_data_to_big_query(data, **kwargs) -> None:
    """
    Template for exporting data to a BigQuery warehouse.
    Specify your configuration settings in 'io_config.yaml'.

    Docs: https://docs.mage.ai/design/data-loading#bigquery

    """

    config_path = path.join(get_repo_path(), 'io_config.yaml')
    config_profile = 'default'

    for key, value in data.items():
        table_id = 'yellow-taxi-analysis-shumehta.taxi_dataset_shumehta.{}'.format(key)
        BigQuery.with_config(ConfigFileLoader(config_path, config_profile)).export(
            DataFrame(value),
            table_id,
            if_exists='replace',  # Specify resolution policy if table name already exists
        )
