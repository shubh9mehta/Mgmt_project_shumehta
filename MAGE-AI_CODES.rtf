{\rtf1\ansi\ansicpg1252\cocoartf2758
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica-BoldOblique;\f1\fswiss\fcharset0 Helvetica;\f2\fmodern\fcharset0 Courier;
\f3\fmodern\fcharset0 Courier-BoldOblique;\f4\fmodern\fcharset0 Courier-Oblique;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red0\green0\blue0;\red193\green152\blue86;
\red255\green255\blue255;\red125\green141\blue87;\red212\green212\blue212;\red70\green137\blue204;\red76\green72\blue77;
\red167\green197\blue152;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\csgray\c0\c0;\cssrgb\c80392\c65882\c41176;
\cssrgb\c100000\c100000\c100000;\cssrgb\c56078\c61569\c41569;\cssrgb\c86275\c86275\c86275;\cssrgb\c33725\c61176\c83922;\cssrgb\c37255\c35294\c37647;
\cssrgb\c70980\c80784\c65882;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\i\b\fs24 \cf2 \cb3 Mage ai files \
\
DATA LODER 
\f1\i0\b0 \
\
\pard\pardeftab720\partightenfactor0

\f2\fs28 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 import\strokec5  io\
\strokec4 import\strokec5  pandas \strokec4 as\strokec5  pd\
\strokec4 import\strokec5  requests\
\strokec4 if\strokec5  \strokec6 'data_loader'\strokec5  \strokec4 not\strokec5  \strokec4 in\strokec5  \strokec4 globals\strokec7 ():\strokec5 \
    \strokec4 from\strokec5  mage_ai.data_preparation.decorators \strokec4 import\strokec5  data_loader\
\strokec4 if\strokec5  \strokec6 'test'\strokec5  \strokec4 not\strokec5  \strokec4 in\strokec5  \strokec4 globals\strokec7 ():\strokec5 \
    \strokec4 from\strokec5  mage_ai.data_preparation.decorators \strokec4 import\strokec5  test\
\
\
\pard\pardeftab720\partightenfactor0
\cf2 \strokec8 @data_loader\strokec5 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec4 def\strokec5  load_data_from_api\strokec7 (\strokec5 *args\strokec7 ,\strokec5  **kwargs\strokec7 ):\strokec5 \
    \strokec6 """\strokec5 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec6     Template for loading data from API\strokec5 \
\strokec6     """\strokec5 \
    url = \strokec6 'https://storage.googleapis.com/taxi-data-analysis-shumehta/Final_dataset_taxi.csv'\strokec5 \
    response = requests.get\strokec7 (\strokec5 url\strokec7 )\strokec5 \
\
    \strokec4 return\strokec5  pd.read_csv\strokec7 (\strokec5 io.StringIO\strokec7 (\strokec5 response.text\strokec7 ),\strokec5  sep=\strokec6 ','\strokec7 )\strokec5 \
\
\
\pard\pardeftab720\partightenfactor0
\cf2 \strokec8 @test\strokec5 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec4 def\strokec5  test_output\strokec7 (\strokec5 output\strokec7 ,\strokec5  *args\strokec7 )\strokec5  -> \strokec4 None\strokec7 :\strokec5 \
    \strokec6 """\strokec5 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec6     Template code for testing the output of the block.\strokec5 \
\strokec6     """\strokec5 \
    \strokec4 assert\strokec5  output \strokec4 is\strokec5  \strokec4 not\strokec5  \strokec4 None\strokec7 ,\strokec5  \strokec6 'The output is undefined'\
\pard\pardeftab720\partightenfactor0
\cf2 \strokec5 \
\

\f3\i\b DATA TRANSFORMER 
\f2\i0\b0 \
\
\pard\pardeftab720\partightenfactor0
\cf2 \strokec4 import\strokec5  pandas \strokec4 as\strokec5  pd\
\strokec4 if\strokec5  \strokec6 'transformer'\strokec5  \strokec4 not\strokec5  \strokec4 in\strokec5  \strokec4 globals\strokec7 ():\strokec5 \
    \strokec4 from\strokec5  mage_ai.data_preparation.decorators \strokec4 import\strokec5  transformer\
\strokec4 if\strokec5  \strokec6 'test'\strokec5  \strokec4 not\strokec5  \strokec4 in\strokec5  \strokec4 globals\strokec7 ():\strokec5 \
    \strokec4 from\strokec5  mage_ai.data_preparation.decorators \strokec4 import\strokec5  test\
\
\
\pard\pardeftab720\partightenfactor0
\cf2 \strokec8 @transformer\strokec5 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec4 def\strokec5  transform\strokec7 (\strokec5 df\strokec7 ,\strokec5  *args\strokec7 ,\strokec5  **kwargs\strokec7 ):\strokec5 \
    \strokec6 """\strokec5 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec6     Template code for a transformer block.\strokec5 \
\
\strokec6     Add more parameters to this function if this block has multiple parent blocks.\strokec5 \
\strokec6     There should be one parameter for each output variable from each parent block.\strokec5 \
\
\strokec6     Args:\strokec5 \
\strokec6         data: The output from the upstream parent block\strokec5 \
\strokec6         args: The output from any additional upstream blocks (if applicable)\strokec5 \
\
\strokec6     Returns:\strokec5 \
\strokec6         Anything (e.g. data frame, dictionary, array, int, str, etc.)\strokec5 \
\strokec6     """\strokec5 \
    
\f4\i \strokec9 # Specify your transformation logic here
\f2\i0 \strokec5 \
    df\strokec7 [[\strokec6 'tpep_pickup_datetime'\strokec7 ,\strokec5  \strokec6 'tpep_dropoff_datetime'\strokec7 ]]\strokec5  = df\strokec7 [[\strokec6 'tpep_pickup_datetime'\strokec7 ,\strokec5  \strokec6 'tpep_dropoff_datetime'\strokec7 ]]\strokec5 .\strokec4 apply\strokec7 (\strokec5 pd.to_datetime\strokec7 )\strokec5 \
\
    
\f4\i \strokec9 # Remove duplicates from the DataFrame and reset the index without adding the old index as a column.
\f2\i0 \strokec5 \
    df = df.drop_duplicates\strokec7 ()\strokec5 .reset_index\strokec7 (\strokec5 drop=\strokec4 True\strokec7 )\strokec5 \
    
\f4\i \strokec9 # Create a new column 'trip_id' which is just the new index of each row.
\f2\i0 \strokec5 \
    df\strokec7 [\strokec6 'trip_id'\strokec7 ]\strokec5  = df.index\
\
    
\f4\i \strokec9 # Extract only the pickup and dropoff datetime columns and reset the index to ensure alignment.
\f2\i0 \strokec5 \
    datetime_dim = df\strokec7 [[\strokec6 'tpep_pickup_datetime'\strokec7 ,\strokec5  \strokec6 'tpep_dropoff_datetime'\strokec7 ]]\strokec5 .copy\strokec7 ()\strokec5 \
\
    
\f4\i \strokec9 # Extract various datetime components from the pickup and dropoff datetime columns.
\f2\i0 \strokec5 \
    datetime_features = \strokec7 [\strokec6 'hour'\strokec7 ,\strokec5  \strokec6 'day'\strokec7 ,\strokec5  \strokec6 'month'\strokec7 ,\strokec5  \strokec6 'year'\strokec7 ,\strokec5  \strokec6 'weekday'\strokec7 ]\strokec5 \
    \strokec4 for\strokec5  feature \strokec4 in\strokec5  datetime_features\strokec7 :\strokec5 \
        datetime_dim\strokec7 [\strokec5 f\strokec6 'pick_\{feature\}'\strokec7 ]\strokec5  = datetime_dim\strokec7 [\strokec6 'tpep_pickup_datetime'\strokec7 ]\strokec5 .dt.__getattribute__\strokec7 (\strokec5 feature\strokec7 )\strokec5 \
        datetime_dim\strokec7 [\strokec5 f\strokec6 'drop_\{feature\}'\strokec7 ]\strokec5  = datetime_dim\strokec7 [\strokec6 'tpep_dropoff_datetime'\strokec7 ]\strokec5 .dt.__getattribute__\strokec7 (\strokec5 feature\strokec7 )\strokec5 \
\
    
\f4\i \strokec9 # Assign a unique ID to each row in the datetime_dim DataFrame which is just its index.
\f2\i0 \strokec5 \
    datetime_dim\strokec7 [\strokec6 'datetime_id'\strokec7 ]\strokec5  = datetime_dim.index\
\
    
\f4\i \strokec9 # Reorder columns to match the specified order.
\f2\i0 \strokec5 \
    columns_order = \strokec7 [\strokec6 'datetime_id'\strokec7 ,\strokec5  \strokec6 'tpep_pickup_datetime'\strokec7 ]\strokec5  + \strokec7 [\strokec5 f\strokec6 'pick_\{feature\}'\strokec5  \strokec4 for\strokec5  feature \strokec4 in\strokec5  datetime_features\strokec7 ]\strokec5  + \\\
                    \strokec7 [\strokec6 'tpep_dropoff_datetime'\strokec7 ]\strokec5  + \strokec7 [\strokec5 f\strokec6 'drop_\{feature\}'\strokec5  \strokec4 for\strokec5  feature \strokec4 in\strokec5  datetime_features\strokec7 ]\strokec5 \
    datetime_dim = datetime_dim\strokec7 [\strokec5 columns_order\strokec7 ]\strokec5 \
\
    
\f4\i \strokec9 # Create a dimension table for passenger counts
\f2\i0 \strokec5 \
    passenger_count_dim = df\strokec7 [[\strokec6 'passenger_count'\strokec7 ]]\strokec5 .drop_duplicates\strokec7 ()\strokec5 .reset_index\strokec7 (\strokec5 drop=\strokec4 True\strokec7 )\strokec5 \
    passenger_count_dim\strokec7 [\strokec6 'passenger_count_id'\strokec7 ]\strokec5  = passenger_count_dim.index\
\
    
\f4\i \strokec9 # Create a dimension table for trip distances
\f2\i0 \strokec5 \
    trip_distance_dim = df\strokec7 [[\strokec6 'trip_distance'\strokec7 ]]\strokec5 .drop_duplicates\strokec7 ()\strokec5 .reset_index\strokec7 (\strokec5 drop=\strokec4 True\strokec7 )\strokec5 \
    trip_distance_dim\strokec7 [\strokec6 'trip_distance_id'\strokec7 ]\strokec5  = trip_distance_dim.index\
\
    
\f4\i \strokec9 # Define a mapping dictionary for rate codes
\f2\i0 \strokec5 \
    rate_code_type = \strokec7 \{\strokec5 \
        \strokec10 1\strokec7 :\strokec5  \strokec6 "Standard rate"\strokec7 ,\strokec5 \
        \strokec10 2\strokec7 :\strokec5  \strokec6 "JFK"\strokec7 ,\strokec5 \
        \strokec10 3\strokec7 :\strokec5  \strokec6 "Newark"\strokec7 ,\strokec5 \
        \strokec10 4\strokec7 :\strokec5  \strokec6 "Nassau or Westchester"\strokec7 ,\strokec5 \
        \strokec10 5\strokec7 :\strokec5  \strokec6 "Negotiated fare"\strokec7 ,\strokec5 \
        \strokec10 6\strokec7 :\strokec5  \strokec6 "Group ride"\strokec5 \
        \strokec7 \}\strokec5 \
\
    
\f4\i \strokec9 # Create a dimension table for rate codes
\f2\i0 \strokec5 \
    rate_code_dim = df\strokec7 [[\strokec6 'RatecodeID'\strokec7 ]]\strokec5 .drop_duplicates\strokec7 ()\strokec5 .reset_index\strokec7 (\strokec5 drop=\strokec4 True\strokec7 )\strokec5 \
    rate_code_dim\strokec7 [\strokec6 'rate_code_id'\strokec7 ]\strokec5  = rate_code_dim.index\
    rate_code_dim\strokec7 [\strokec6 'rate_code_name'\strokec7 ]\strokec5  = rate_code_dim\strokec7 [\strokec6 'RatecodeID'\strokec7 ]\strokec5 .\strokec4 map\strokec7 (\strokec5 rate_code_type\strokec7 )\strokec5 \
\
    
\f4\i \strokec9 #reorder the columns
\f2\i0 \strokec5 \
    rate_code_dim = rate_code_dim\strokec7 [[\strokec6 'rate_code_id'\strokec7 ,\strokec5  \strokec6 'RatecodeID'\strokec7 ,\strokec5  \strokec6 'rate_code_name'\strokec7 ]]\strokec5 \
\
    \strokec4 def\strokec5  create_location_dim\strokec7 (\strokec5 df\strokec7 ,\strokec5  location_id_column\strokec7 ,\strokec5  location_dim_name\strokec7 ):\strokec5 \
  \
        location_dim = df\strokec7 [[\strokec5 location_id_column\strokec7 ]]\strokec5 .drop_duplicates\strokec7 ()\strokec5 .reset_index\strokec7 (\strokec5 drop=\strokec4 True\strokec7 )\strokec5 \
        location_dim\strokec7 [\strokec5 location_dim_name\strokec7 ]\strokec5  = location_dim.index\
        \strokec4 return\strokec5  location_dim\
\
    
\f4\i \strokec9 # Creating pickup and dropoff dimension tables
\f2\i0 \strokec5 \
    pickup_location_dim = create_location_dim\strokec7 (\strokec5 df\strokec7 ,\strokec5  \strokec6 'PULocationID'\strokec7 ,\strokec5  \strokec6 'pickup_location_id'\strokec7 )\strokec5 \
    dropoff_location_dim = create_location_dim\strokec7 (\strokec5 df\strokec7 ,\strokec5  \strokec6 'DOLocationID'\strokec7 ,\strokec5  \strokec6 'dropoff_location_id'\strokec7 )\strokec5 \
\
    
\f4\i \strokec9 # Dictionary mapping payment types to descriptive names
\f2\i0 \strokec5 \
    payment_type_name = \strokec7 \{\strokec5 \
        \strokec10 1\strokec7 :\strokec5  \strokec6 "Credit card"\strokec7 ,\strokec5 \
        \strokec10 2\strokec7 :\strokec5  \strokec6 "Cash"\strokec7 ,\strokec5 \
        \strokec10 3\strokec7 :\strokec5  \strokec6 "No charge"\strokec7 ,\strokec5 \
        \strokec10 4\strokec7 :\strokec5  \strokec6 "Dispute"\strokec7 ,\strokec5 \
        \strokec10 5\strokec7 :\strokec5  \strokec6 "Unknown"\strokec7 ,\strokec5 \
        \strokec10 6\strokec7 :\strokec5  \strokec6 "Voided trip"\strokec5 \
    \strokec7 \}\strokec5 \
\
    
\f4\i \strokec9 # Function to create a payment type dimension table
\f2\i0 \strokec5 \
    \strokec4 def\strokec5  create_payment_type_dim\strokec7 (\strokec5 df\strokec7 ,\strokec5  col_name\strokec7 ,\strokec5  mapping_dict\strokec7 ):\strokec5 \
\
        payment_type_dim = df\strokec7 [[\strokec5 col_name\strokec7 ]]\strokec5 .drop_duplicates\strokec7 ()\strokec5 .reset_index\strokec7 (\strokec5 drop=\strokec4 True\strokec7 )\strokec5 \
        payment_type_dim\strokec7 [\strokec6 'payment_type_id'\strokec7 ]\strokec5  = payment_type_dim.index\
        payment_type_dim\strokec7 [\strokec6 'payment_type_name'\strokec7 ]\strokec5  = payment_type_dim\strokec7 [\strokec5 col_name\strokec7 ]\strokec5 .\strokec4 map\strokec7 (\strokec5 mapping_dict\strokec7 )\strokec5 \
        \strokec4 return\strokec5  payment_type_dim\strokec7 [[\strokec6 'payment_type_id'\strokec7 ,\strokec5  col_name\strokec7 ,\strokec5  \strokec6 'payment_type_name'\strokec7 ]]\strokec5 \
\
    
\f4\i \strokec9 # Creating the payment type dimension table
\f2\i0 \strokec5 \
    payment_type_dim = create_payment_type_dim\strokec7 (\strokec5 df\strokec7 ,\strokec5  \strokec6 'payment_type'\strokec7 ,\strokec5  payment_type_name\strokec7 )\strokec5 \
\
    fact_table = df \\\
    .merge\strokec7 (\strokec5 passenger_count_dim\strokec7 ,\strokec5  left_on=\strokec6 'trip_id'\strokec7 ,\strokec5  right_on=\strokec6 'passenger_count_id'\strokec7 ,\strokec5  how=\strokec6 'left'\strokec7 )\strokec5  \\\
    .merge\strokec7 (\strokec5 trip_distance_dim\strokec7 ,\strokec5  left_on=\strokec6 'trip_id'\strokec7 ,\strokec5  right_on=\strokec6 'trip_distance_id'\strokec7 ,\strokec5  how=\strokec6 'left'\strokec7 )\strokec5  \\\
    .merge\strokec7 (\strokec5 rate_code_dim\strokec7 ,\strokec5  left_on=\strokec6 'RatecodeID'\strokec7 ,\strokec5  right_on=\strokec6 'rate_code_id'\strokec7 ,\strokec5  how=\strokec6 'left'\strokec7 )\strokec5  \\\
    .merge\strokec7 (\strokec5 pickup_location_dim\strokec7 ,\strokec5  left_on=\strokec6 'PULocationID'\strokec7 ,\strokec5  right_on=\strokec6 'pickup_location_id'\strokec7 ,\strokec5  how=\strokec6 'left'\strokec7 )\strokec5  \\\
    .merge\strokec7 (\strokec5 dropoff_location_dim\strokec7 ,\strokec5  left_on=\strokec6 'DOLocationID'\strokec7 ,\strokec5  right_on=\strokec6 'dropoff_location_id'\strokec7 ,\strokec5  how=\strokec6 'left'\strokec7 )\strokec5  \\\
    .merge\strokec7 (\strokec5 datetime_dim\strokec7 ,\strokec5  left_on=\strokec6 'trip_id'\strokec7 ,\strokec5  right_on=\strokec6 'datetime_id'\strokec7 ,\strokec5  how=\strokec6 'left'\strokec7 )\strokec5  \\\
    .merge\strokec7 (\strokec5 payment_type_dim\strokec7 ,\strokec5  left_on=\strokec6 'payment_type'\strokec7 ,\strokec5  right_on=\strokec6 'payment_type_id'\strokec7 ,\strokec5  how=\strokec6 'left'\strokec7 )\strokec5  \\\
    .reindex\strokec7 (\strokec5 columns=\strokec7 [\strokec6 'trip_id'\strokec7 ,\strokec5  \strokec6 'VendorID'\strokec7 ,\strokec5  \strokec6 'datetime_id'\strokec7 ,\strokec5  \strokec6 'passenger_count_id'\strokec7 ,\strokec5 \
                      \strokec6 'trip_distance_id'\strokec7 ,\strokec5  \strokec6 'rate_code_id'\strokec7 ,\strokec5  \strokec6 'store_and_fwd_flag'\strokec7 ,\strokec5  \strokec6 'pickup_location_id'\strokec7 ,\strokec5  \
                      \strokec6 'dropoff_location_id'\strokec7 ,\strokec5  \strokec6 'payment_type_id'\strokec7 ,\strokec5  \strokec6 'fare_amount'\strokec7 ,\strokec5  \strokec6 'extra'\strokec7 ,\strokec5  \strokec6 'mta_tax'\strokec7 ,\strokec5  \
                      \strokec6 'tip_amount'\strokec7 ,\strokec5  \strokec6 'tolls_amount'\strokec7 ,\strokec5  \strokec6 'improvement_surcharge'\strokec7 ,\strokec5  \strokec6 'total_amount'\strokec7 ])\strokec5 \
\
    \strokec4 return\strokec5  \strokec6 "success"\strokec5 \
\
\
\
  \
\
\
\pard\pardeftab720\partightenfactor0
\cf2 \strokec8 @test\strokec5 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec4 def\strokec5  test_output\strokec7 (\strokec5 output\strokec7 ,\strokec5  *args\strokec7 )\strokec5  -> \strokec4 None\strokec7 :\strokec5 \
    \strokec6 """\strokec5 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec6     Template code for testing the output of the block.\strokec5 \
\strokec6     """\strokec5 \
    \strokec4 assert\strokec5  output \strokec4 is\strokec5  \strokec4 not\strokec5  \strokec4 None\strokec7 ,\strokec5  \strokec6 'The output is undefined'\
\

\f3\i\b DATA EXPORTER\

\f4\b0 \
\pard\pardeftab720\partightenfactor0

\f2\i0 \cf2 \strokec5 from mage_ai.settings.repo import get_repo_path\
from mage_ai.io.bigquery import BigQuery\
from mage_ai.io.config import ConfigFileLoader\
from pandas import DataFrame\
from os import path\
\
\
\
if 'data_exporter' not in globals():\
    from mage_ai.data_preparation.decorators import data_exporter\
\
\
@data_exporter\
def export_data_to_big_query(data, **kwargs) -> None:\
    """\
    Template for exporting data to a BigQuery warehouse.\
    Specify your configuration settings in 'io_config.yaml'.\
\
    Docs: https://docs.mage.ai/design/data-loading#bigquery\
\
    """\
\
    config_path = path.join(get_repo_path(), 'io_config.yaml')\
    config_profile = 'default'\
\
    for key, value in data.items():\
        table_id = 'yellow-taxi-analysis-shumehta.taxi_dataset_shumehta.\{\}'.format(key)\
        BigQuery.with_config(ConfigFileLoader(config_path, config_profile)).export(\
            DataFrame(value),\
            table_id,\
            if_exists='replace',  # Specify resolution policy if table name already exists\
        )}